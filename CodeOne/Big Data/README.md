
# Don’t Worry! How to Build a Data Lake in Oracle Big Data Service - BYOL [HOL2225]

## Abstract

Data volume worldwide is increasing by the second every day. Efficient methods are needed to handle this immense data growth and complexity. Having a data lake is an easy and fast way to store structured and unstructured data in a central repository. The data can be used for different purposes such as dashboards, big data processing, real-time analyses, or machine learning. 

This hands-on lab uses open source NYC bike rental data to build a data lake and load and stream the data from object storage in real time to get some quick insights and even build an interactive map. The session uses technologies such as Hive, Spark, Kafka, Python, Zeppelin, and object storage. 

## Introduction

Oracle offers a set of Big Data Journeys to help users get started using Oracle Cloud services with a purpose. This particular journey is designed to show you techniques you can use to build your own New Data Lake.

You will learn how to populate and analyze your data lake from a variety of file and streaming sources. You will learn how to execute real-time and batch processing with Oracle’s managed Hive, Spark, Kafka and Object Storage services in the cloud.


